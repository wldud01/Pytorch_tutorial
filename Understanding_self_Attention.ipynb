{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO5ndiMuOjiaNx1Y4UGbR/J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wldud01/Pytorch_tutorial/blob/main/Understanding_self_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do4mY7W_I-kJ",
        "outputId": "21eff7e5-24a4-4752-f852-d3d549f9fb04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'디저트를': 0, '먹습니다.': 1, '반갑습니다.': 2, '안녕하세요.': 3, '인생은': 4, '짧고': 5, '처음': 6}\n"
          ]
        }
      ],
      "source": [
        "#@title Embedding sentence\n",
        "\n",
        "sentence = \"안녕하세요. 반갑습니다. 인생은 짧고 처음 디저트를 먹습니다.\"\n",
        "\n",
        "dc = {s:i for i,s in enumerate(sorted(sentence.split()))}\n",
        "\n",
        "print(dc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# next we assign an integer index to each word\n",
        "\n",
        "import torch\n",
        "\n",
        "sentence_int = torch.tensor(\n",
        "    [dc[s] for s in sentence.split()]\n",
        ")\n",
        "print(sentence_int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47lqEFqAJhp9",
        "outputId": "3b5b2144-d7d7-4791-9b01-3ee9a4ee7c04"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 2, 4, 5, 6, 0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50_000\n",
        "\n",
        "torch.manual_seed(123)\n",
        "# embedding layer\n",
        "embed = torch.nn.Embedding(vocab_size,3)\n",
        "embedded_sentence = embed(sentence_int).detach()\n",
        "\n",
        "print(embedded_sentence)\n",
        "print(embedded_sentence.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv64thEFKTd9",
        "outputId": "2aa38136-30b5-4fc2-91b9-17b23f2ba6e8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.1925,  0.6984, -1.4097],\n",
            "        [-0.2196, -0.3792,  0.7671],\n",
            "        [ 0.1794,  1.8951,  0.4954],\n",
            "        [ 0.2692, -0.0770, -1.0205],\n",
            "        [-0.1690,  0.9178,  1.5810],\n",
            "        [ 0.3374, -0.1778, -0.3035],\n",
            "        [-0.5880,  0.3486,  0.6603]])\n",
            "torch.Size([7, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "# embedding token\n",
        "d= embedded_sentence.shape[1]\n",
        "print(d)\n",
        "\n",
        "# q-dimension and k-dimension is same\n",
        "# v-dimension is arbitary\n",
        "d_q,d_k,d_v = 2,2,4\n",
        "\n",
        "W_query = torch.nn.Parameter(torch.rand(d,d_q))# 3,2\n",
        "W_key = torch.nn.Parameter(torch.rand(d,d_k)) # 3,2\n",
        "W_value = torch.nn.Parameter(torch.rand(d,d_v)) # 3,4\n",
        "\n",
        "print(W_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojeYlKKd4yrv",
        "outputId": "777a0f7f-4210-40b0-ece7-601787e4a798"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "Parameter containing:\n",
            "tensor([[0.2961, 0.5166],\n",
            "        [0.2517, 0.6886],\n",
            "        [0.0740, 0.8665]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_2 = embedded_sentence[1]\n",
        "print(x_2)\n",
        "\n",
        "# x_2의 query key value\n",
        "query_2 = x_2@ W_query\n",
        "key_2 = x_2@W_key\n",
        "value_2 = x_2@W_value\n",
        "\n",
        "print(query_2.shape)\n",
        "print(query_2)\n",
        "print(key_2.shape)\n",
        "print(value_2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x8XKOW05iTK",
        "outputId": "0ad40eae-da3f-48dd-f991-0763a644051a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.2196, -0.3792,  0.7671])\n",
            "torch.Size([2])\n",
            "tensor([-0.1037,  0.2902], grad_fn=<SqueezeBackward4>)\n",
            "torch.Size([2])\n",
            "torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# whole key and value using embedded sentence\n",
        "keys = embedded_sentence @ W_key\n",
        "values = embedded_sentence @ W_value\n",
        "\n",
        "print(keys[4])\n",
        "print(\"key,shape:\", keys.shape)\n",
        "print(\"values.shape\", values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy7BQjUO57nw",
        "outputId": "9b7b02ae-fac7-4d65-a400-5387f32fe18e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.6443, 1.7357], grad_fn=<SelectBackward0>)\n",
            "key,shape: torch.Size([7, 2])\n",
            "values.shape torch.Size([7, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_2 의 query를 전체 embedded sentence의 key matrices와 dot product\n",
        "print(\"query_2\", query_2)\n",
        "omega_24 = query_2.dot(keys[4])\n",
        "print(omega_24)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FHm_X606R_c",
        "outputId": "b178132c-eac3-4b00-896a-c936d3b9180e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query_2 tensor([-0.1037,  0.2902], grad_fn=<SqueezeBackward4>)\n",
            "tensor(0.4368, grad_fn=<DotBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "omega_2 = query_2 @ keys.T # 1x2  2x7 =  1x7\n",
        "print(omega_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STV_hXhQ6ggN",
        "outputId": "c9901d23-5c7e-436c-a110-24919ac695c6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1197,  0.0518,  0.4487, -0.1807,  0.4368, -0.0794,  0.1677],\n",
            "       grad_fn=<SqueezeBackward4>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# d_k로 scaling  -> softmax - > proabability distribution\n",
        "attention_weights_2 = F.softmax(omega_2/d_k**0.5,dim=0)\n",
        "print(attention_weights_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZN5CS7470gk",
        "outputId": "2a10bfb2-e028-45a2-dfa2-c03ae660ecdc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1202, 0.1357, 0.1797, 0.1151, 0.1782, 0.1237, 0.1473],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# softmax를 거친 attention weights를 value값과 cardinary product\n",
        "context_vector_2 = attention_weights_2 @ values\n",
        "\n",
        "print(context_vector_2.shape)\n",
        "print(context_vector_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GkufRP68wQL",
        "outputId": "4137029f-110b-48ce-adfd-596f9c047a37"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4])\n",
            "tensor([0.2634, 0.5714, 0.3120, 0.5370], grad_fn=<SqueezeBackward4>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Self attention\n",
        "import torch.nn as nn\n",
        "class SelfAttention(nn.Module):\n",
        "\n",
        "  # initialize\n",
        "  def __init__(self,d_in, d_out_kq, d_put_v):\n",
        "    super().__init__()\n",
        "    self.d_out_kq = d_out_kq\n",
        "    self.W_query = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
        "    self.W_key = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
        "    self.W_value = nn.Parameter(torch.rand(d_in, d_put_v))\n",
        "\n",
        "  # forward pass\n",
        "  def forward(self,x):\n",
        "    # key query value represent\n",
        "    keys = x @ self.W_key\n",
        "    queries = x @ self.W_query\n",
        "    values = x @ self.W_value\n",
        "\n",
        "    # make attention score and attention weights probability\n",
        "    attn_scores = queries @ keys.T\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores/self.d_out_kq**0.5, dim = -1\n",
        "    )\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "fPETNr0T8_W5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "# reduce d_out_v from 4 to 1 because we have 4 head\n",
        "\n",
        "d_in, d_out_kq,d_out_v = 3,2,4\n",
        "\n",
        "# Self Attention module\n",
        "sa = SelfAttention(d_in,d_out_kq,d_out_v)\n",
        "print(sa(embedded_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJrzmrXZ-1Oy",
        "outputId": "7b57e498-de2e-418c-a1d3-b4a726a20069"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4831, -0.2340, -0.3703, -0.5371],\n",
            "        [ 0.2634,  0.5714,  0.3120,  0.5370],\n",
            "        [ 0.9139,  1.4875,  1.0045,  1.6377],\n",
            "        [-0.2496, -0.0196, -0.1716, -0.2275],\n",
            "        [ 0.9082,  1.4865,  1.0015,  1.6333],\n",
            "        [ 0.0316,  0.2859,  0.0857,  0.1780],\n",
            "        [ 0.3908,  0.7338,  0.4397,  0.7393]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionWrapper(nn.Module):\n",
        "\n",
        "  def __init__(self, d_in, d_out_kq, d_out_v, num_heads):\n",
        "    super().__init__()\n",
        "    # iteration\n",
        "    self.heads = nn.ModuleList(\n",
        "        [SelfAttention(d_in,d_out_kq,d_out_v)\n",
        "        for _ in range(num_heads)]\n",
        "    )\n",
        "\n",
        "  # forward pass\n",
        "  def forward(self,x):\n",
        "    return torch.cat([head(x) for head in self.heads], dim = -1)"
      ],
      "metadata": {
        "id": "K3M542A7_You"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "d_in, d_out_kq, d_out_v = 3, 2, 1\n",
        "\n",
        "sa  = SelfAttention(d_in,d_out_kq,d_out_v)\n",
        "print(sa(embedded_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIjhcjz6Ab0C",
        "outputId": "e530e722-ab68-46e2-c245-ecb165b519ee"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1627],\n",
            "        [ 0.1739],\n",
            "        [ 0.5123],\n",
            "        [-0.0651],\n",
            "        [ 0.5108],\n",
            "        [ 0.0621],\n",
            "        [ 0.2366]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "block_size = embedded_sentence.shape[1]\n",
        "mha = MultiHeadAttentionWrapper(\n",
        "    d_in,d_out_kq, d_out_v, num_heads = 4\n",
        ")\n",
        "context_vecs = mha(embedded_sentence)\n",
        "\n",
        "print(context_vecs)\n",
        "print(\"context vector shape\", context_vecs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETvDpQjgAp02",
        "outputId": "d2087d53-e6da-4a9b-f864-01db8f45ed36"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1627, -0.1817, -0.1925, -0.2708],\n",
            "        [ 0.1739,  0.4257,  0.4324,  0.1601],\n",
            "        [ 0.5123,  1.4266,  1.4526,  0.9668],\n",
            "        [-0.0651, -0.1244,  0.1373, -0.1819],\n",
            "        [ 0.5108,  1.4200,  1.3082,  0.9486],\n",
            "        [ 0.0621,  0.0892,  0.3831, -0.0157],\n",
            "        [ 0.2366,  0.7066,  0.5258,  0.3166]], grad_fn=<CatBackward0>)\n",
            "context vector shape torch.Size([7, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cross Attention\n",
        "import torch.nn as nn\n",
        "\n",
        "class CrossAttention(nn.Module):\n",
        "\n",
        "  def __init__(self, d_in, d_out_qk, d_out_v):\n",
        "    super().__init__()\n",
        "    self.d_out_kq = d_out_qk\n",
        "    self.W_query = nn.Parameter(torch.rand(d_in,d_out_kq))\n",
        "    self.W_key = nn.Parameter(torch.rand(d_in,d_out_kq))\n",
        "    self.W_value = nn.Parameter(torch.rand(d_in,d_out_v))\n",
        "\n",
        "  def forward(self, x_1, x_2):\n",
        "    # decoder input query\n",
        "    queries_1 = x_1 @ self.W_query\n",
        "\n",
        "    # encoder context vector\n",
        "    keys_2 = x_2 @ self.W_key\n",
        "    values_2 = x_2 @ self.W_value\n",
        "\n",
        "    attn_scores = queries_1 @ keys_2.T\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores/self.d_out_kq**0.5, dim = -1\n",
        "    )\n",
        "    context_vec = attn_weights @ values_2\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "Okrj39AwA-Hj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.manual_seed(123)\n",
        "\n",
        "d_in, d_out_kq, d_out_v = 3,2,4\n",
        "\n",
        "crossattn = CrossAttention(d_in,d_out_kq,d_out_v)\n",
        "\n",
        "first_input = embedded_sentence\n",
        "second_input = torch.rand(8,d_in)\n",
        "\n",
        "print('first input shape', first_input.shape)\n",
        "print(\"second input shape\", second_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir-4o_0H2fAx",
        "outputId": "1ae16f91-cc7a-452d-bd60-07dcdad0930e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first input shape torch.Size([7, 3])\n",
            "second input shape torch.Size([8, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x_1 ,x_2\n",
        "context_vectors = crossattn(first_input, second_input)\n",
        "\n",
        "print(context_vectors)\n",
        "print(\"output shape\", context_vectors.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKYYpdwv2-9w",
        "outputId": "6b477d0c-4204-4bc5-ea7c-89930c260ddf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3860, 0.8021, 0.5985, 0.9250],\n",
            "        [0.4357, 0.8886, 0.6678, 1.0311],\n",
            "        [0.4874, 0.9718, 0.7359, 1.1353],\n",
            "        [0.4054, 0.8359, 0.6258, 0.9667],\n",
            "        [0.4863, 0.9709, 0.7347, 1.1336],\n",
            "        [0.4231, 0.8665, 0.6503, 1.0042],\n",
            "        [0.4429, 0.9006, 0.6775, 1.0460]], grad_fn=<MmBackward0>)\n",
            "output shape torch.Size([7, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Causal attention\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "d_in, d_out_kq, d_out_v = 3,2,4\n",
        "\n",
        "W_query = nn.Parameter(torch.rand(d_in,d_out_kq))\n",
        "W_key = nn.Parameter(torch.rand(d_in,d_out_kq))\n",
        "W_value = nn.Parameter(torch.rand(d_in,d_out_v))\n",
        "\n",
        "x = embedded_sentence\n",
        "\n",
        "keys = x @ W_key\n",
        "queries = x @ W_query\n",
        "values = x @ W_value\n",
        "\n",
        "attn_scores = queries @ keys.T\n",
        "attn_weights = torch.softmax(\n",
        "    attn_scores/d_out_kq**0.5,dim = 1\n",
        ")\n",
        "\n",
        "print(attn_scores)\n",
        "print(attn_scores.shape)\n",
        "print(\"\")\n",
        "print(\"Attention weights\" ,\"\\n\",attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trQZx5nA3VqI",
        "outputId": "6130b333-d99e-4b4f-c207-15a5bff97407"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.9265, -0.3509, -2.5037,  1.0740, -2.5363,  0.4344, -0.9315],\n",
            "        [-0.1197,  0.0518,  0.4487, -0.1807,  0.4368, -0.0794,  0.1677],\n",
            "        [-1.3374,  0.4991,  3.4707, -1.5023,  3.5360, -0.6004,  1.2903],\n",
            "        [ 0.4730, -0.1851, -1.3934,  0.5869, -1.3953,  0.2432, -0.5191],\n",
            "        [-1.2598,  0.4810,  3.4806, -1.4859,  3.5151, -0.6049,  1.2954],\n",
            "        [ 0.1076, -0.0437, -0.3491,  0.1443, -0.3454,  0.0613, -0.1303],\n",
            "        [-0.2787,  0.1112,  0.8626, -0.3597,  0.8584, -0.1510,  0.3216]],\n",
            "       grad_fn=<MmBackward0>)\n",
            "torch.Size([7, 7])\n",
            "\n",
            "Attention weights \n",
            " tensor([[0.2729, 0.1106, 0.0241, 0.3028, 0.0236, 0.1927, 0.0733],\n",
            "        [0.1202, 0.1357, 0.1797, 0.1151, 0.1782, 0.1237, 0.1473],\n",
            "        [0.0133, 0.0489, 0.3995, 0.0119, 0.4184, 0.0225, 0.0855],\n",
            "        [0.2178, 0.1368, 0.0582, 0.2360, 0.0581, 0.1851, 0.1080],\n",
            "        [0.0141, 0.0484, 0.4035, 0.0120, 0.4135, 0.0224, 0.0861],\n",
            "        [0.1616, 0.1452, 0.1170, 0.1659, 0.1173, 0.1564, 0.1366],\n",
            "        [0.0965, 0.1272, 0.2163, 0.0911, 0.2157, 0.1056, 0.1476]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = attn_scores.shape[0]\n",
        "# diagonal matrix\n",
        "mask_simple = torch.tril(torch.ones(block_size, block_size))\n",
        "print(mask_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgnZ-Yx24Zvz",
        "outputId": "e6e127b2-e355-45ad-ae0d-3e41d37aa0f4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create diagonal matrix and multiple with attn_weigths\n",
        "# zero is for masking future work\n",
        "masked_simple = attn_weights*mask_simple\n",
        "print(masked_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAiKbXzf48bZ",
        "outputId": "8d4b40b5-d956-49b1-8c5c-2899a1346aec"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2729, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1202, 0.1357, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0133, 0.0489, 0.3995, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2178, 0.1368, 0.0582, 0.2360, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0141, 0.0484, 0.4035, 0.0120, 0.4135, 0.0000, 0.0000],\n",
            "        [0.1616, 0.1452, 0.1170, 0.1659, 0.1173, 0.1564, 0.0000],\n",
            "        [0.0965, 0.1272, 0.2163, 0.0911, 0.2157, 0.1056, 0.1476]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sum each col\n",
        "row_sums = masked_simple.sum(dim=1, keepdim = True)\n",
        "# scaling vector\n",
        "masked_simple_norm = masked_simple/row_sums\n",
        "\n",
        "print(row_sums)\n",
        "print(masked_simple_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZK6BJpf5Io-",
        "outputId": "b7c932e0-47d4-48fb-e7ff-0162e14e76ce"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2729],\n",
            "        [0.2559],\n",
            "        [0.4617],\n",
            "        [0.6488],\n",
            "        [0.8915],\n",
            "        [0.8634],\n",
            "        [1.0000]], grad_fn=<SumBackward1>)\n",
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4697, 0.5303, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0289, 0.1058, 0.8653, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3357, 0.2108, 0.0897, 0.3638, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0158, 0.0543, 0.4526, 0.0135, 0.4638, 0.0000, 0.0000],\n",
            "        [0.1872, 0.1682, 0.1355, 0.1921, 0.1359, 0.1812, 0.0000],\n",
            "        [0.0965, 0.1272, 0.2163, 0.0911, 0.2157, 0.1056, 0.1476]],\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# more efficient method\n",
        "\n",
        "# Upper triangle\n",
        "mask = torch.triu(torch.ones(block_size,block_size),diagonal=1)\n",
        "print(mask)\n",
        "\n",
        "# positive mask values with -torch.inf\n",
        "masked = attn_scores.masked_fill(mask.bool(),-torch.inf)\n",
        "print(masked)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILFzUtWn5pfO",
        "outputId": "1ad418fb-1596-4139-bfe1-d7618cc8eb50"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 1., 1., 1., 1., 1., 1.],\n",
            "        [0., 0., 1., 1., 1., 1., 1.],\n",
            "        [0., 0., 0., 1., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0.]])\n",
            "tensor([[ 0.9265,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
            "        [-0.1197,  0.0518,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
            "        [-1.3374,  0.4991,  3.4707,    -inf,    -inf,    -inf,    -inf],\n",
            "        [ 0.4730, -0.1851, -1.3934,  0.5869,    -inf,    -inf,    -inf],\n",
            "        [-1.2598,  0.4810,  3.4806, -1.4859,  3.5151,    -inf,    -inf],\n",
            "        [ 0.1076, -0.0437, -0.3491,  0.1443, -0.3454,  0.0613,    -inf],\n",
            "        [-0.2787,  0.1112,  0.8626, -0.3597,  0.8584, -0.1510,  0.3216]],\n",
            "       grad_fn=<MaskedFillBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to apply the softmax function\n",
        "# e^(-inf) approaches 0\n",
        "attn_weights = torch.softmax(masked/d_out_kq**0.5,dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgp9yv1n6P2g",
        "outputId": "514cf7ff-bef0-4b49-956c-0072af8befd9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4697, 0.5303, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0289, 0.1058, 0.8653, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3357, 0.2108, 0.0897, 0.3638, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0158, 0.0543, 0.4526, 0.0135, 0.4638, 0.0000, 0.0000],\n",
            "        [0.1872, 0.1682, 0.1355, 0.1921, 0.1359, 0.1812, 0.0000],\n",
            "        [0.0965, 0.1272, 0.2163, 0.0911, 0.2157, 0.1056, 0.1476]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hhbixhda6rSf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}